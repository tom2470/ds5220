{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb590e78",
   "metadata": {},
   "source": [
    "## Artificial Neural Network in Python \n",
    "\n",
    "This week we have introduced the deep learning and Artificial Neural Networks. Here is the summary:\n",
    "\n",
    "Artificial Neural Networks (ANNs) are computational models inspired by the structure and function of the human brain. ANNs consist of interconnected nodes called neurons or units, organized into layers. The three primary types of layers in ANNs are input, hidden, and output layers.\n",
    "\n",
    "Feedforward Neural Networks (FNNs): FNNs are the simplest type of ANNs where data flows in one direction, from input to output. Each neuron in a layer is connected to every neuron in the subsequent layer.\n",
    "\n",
    "Activation Functions: Neurons apply activation functions to their input, introducing non-linearity into the network. \n",
    "\n",
    "Training ANNs: ANNs are trained using optimization algorithms like gradient descent to minimize a loss or cost function. Backpropagation is a key technique for calculating gradients and updating neuron weights during training. Techniques like dropout, batch normalization, and weight regularization help prevent overfitting in ANNs.\n",
    "\n",
    "Hyperparameter Tuning: Adjusting hyperparameters like the number of layers, neurons, learning rate, and batch size is crucial for optimizing ANN performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09e8360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0-cp310-cp310-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Collecting tensorflow-macos==2.15.0\n",
      "  Using cached tensorflow_macos-2.15.0-cp310-cp310-macosx_12_0_arm64.whl (208.8 MB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_12_0_arm64.whl (1.9 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-macosx_11_0_arm64.whl (35 kB)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (63.2.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.0)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.8.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.10.0-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-macosx_10_9_universal2.whl (1.2 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.59.3-cp310-cp310-macosx_12_0_universal2.whl (9.6 MB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.24.2)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<2,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, astunparse, google-auth, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.4 google-auth-oauthlib-1.1.0 google-pasta-0.2.0 grpcio-1.59.3 h5py-3.10.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.1 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-macos-2.15.0 termcolor-2.3.0 werkzeug-3.0.1 wheel-0.42.0 wrapt-1.14.1\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
      "Call stack:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/__main__.py\", line 31, in <module>\n",
      "    sys.exit(_main())\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='23.3.1'),)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3656c1",
   "metadata": {},
   "source": [
    "### MINST data in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd36c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras #platform to interact with tensorflow\n",
    "from tensorflow.keras.datasets import mnist #import data\n",
    "from tensorflow.keras.models import Sequential #function to define a neural network\n",
    "from tensorflow.keras.layers import Dense, Flatten #the layers\n",
    "from tensorflow.keras.utils import to_categorical #to convert table inot categorical data\n",
    "\n",
    "# Load the MNIST dataset and split it into training and testing sets\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58698f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the pixel value\n",
    "train_images=train_images.astype('float32')/255\n",
    "test_images=test_images.astype('float32')/255\n",
    "\n",
    "#flatten the image to a 1d array\n",
    "train_image=train_images.reshape((60000, 28, 28, 1))\n",
    "test_image=test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "#one hot encoding the labels\n",
    "train_labels= to_categorical(train_labels)\n",
    "test_labels= to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3e9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building neural network\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28,1)),#input layer (only sending information so flatten)\n",
    "    Dense(64, activation= 'relu'),#hidden layer (sending and reciving so dense)\n",
    "    Dense(10,activation='softmax')#output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d81042",
   "metadata": {},
   "source": [
    "The Flatten layer transforms the 2D input images into a 1D array.\n",
    "The Dense layers are fully connected layers responsible for learning patterns and making predictions.\n",
    "\n",
    "The activation functions (ReLU and softmax) introduce non-linearity into the network, allowing it to learn complex relationships in the data.\n",
    "\n",
    "Other options for the activation function: https://www.tensorflow.org/api_docs/python/tf/keras/activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d18036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss = 'categorical_crossentrophy',\n",
    "#               metrics='accuracy')\n",
    "from keras.losses import categorical_crossentropy\n",
    "opt= keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer='adam',\n",
    "              loss = categorical_crossentropy,\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c24bb",
   "metadata": {},
   "source": [
    "Other optimazation algorithm options: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "If it is regression, both loss and metrics can be \"mean_squared_error\". Other options: \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5e6b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 1s 796us/step - loss: 0.3852 - accuracy: 0.8943 - val_loss: 0.2223 - val_accuracy: 0.9379\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 1s 672us/step - loss: 0.1946 - accuracy: 0.9450 - val_loss: 0.1679 - val_accuracy: 0.9528\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 1s 675us/step - loss: 0.1453 - accuracy: 0.9580 - val_loss: 0.1443 - val_accuracy: 0.9593\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 0s 660us/step - loss: 0.1155 - accuracy: 0.9668 - val_loss: 0.1291 - val_accuracy: 0.9611\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 1s 685us/step - loss: 0.0951 - accuracy: 0.9727 - val_loss: 0.1145 - val_accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29cfd3a30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels,epochs= 5,batch_size=64,validation_split =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "227aaf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 377us/step\n",
      "0.9687\n"
     ]
    }
   ],
   "source": [
    "predicted=model.predict(test_images)\n",
    "acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "acc.update_state(test_labels, predicted)\n",
    "print(acc.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188a3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try by yourself: Fit another neural network with 2 layers. One with 64 nodes \n",
    "# and use relu as the activation function while the other one has 32 nodes use \n",
    "# tanh as the activation function. Choose another optimizer and train the model \n",
    "# then print the accuracy.\n",
    "\n",
    "\n",
    "#how to test models\n",
    "#test_loss, testaccuracy = model.evulate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906be87a",
   "metadata": {},
   "source": [
    "### Other options in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c431873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "#to do batch normalization\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28,1)),#input layer (only sending information so flatten)\n",
    "    Dense(64, activation= 'relu'),#hidden layer (sending and reciving so dense)\n",
    "    BatchNormalization(),\n",
    "    Dense(10,activation='softmax')#output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95196a3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'kernel_regularizers')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tomhenehan/Downloads/Code demonstration (6).ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#to do regualization\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregularizers\u001b[39;00m \u001b[39mimport\u001b[39;00m l2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     Flatten(input_shape\u001b[39m=\u001b[39m(\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m,\u001b[39m1\u001b[39m)),\u001b[39m#input layer (only sending information so flatten)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     Dense(\u001b[39m64\u001b[39;49m, activation\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizers \u001b[39m=\u001b[39;49m l2(\u001b[39m0.01\u001b[39;49m)),\u001b[39m#hidden layer (sending and reciving so dense)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     BatchNormalization(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     Dense(\u001b[39m10\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m#output layer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/dtensor/utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[39mif\u001b[39;00m layout:\n\u001b[1;32m     94\u001b[0m             layout_args[variable_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_layout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m layout\n\u001b[0;32m---> 96\u001b[0m init_method(layer_instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m \u001b[39m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m layout_param_name, layout \u001b[39min\u001b[39;00m layout_args\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/core/dense.py:117\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@utils\u001b[39m\u001b[39m.\u001b[39mallow_initializer_layout\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    116\u001b[0m ):\n\u001b[0;32m--> 117\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(activity_regularizer\u001b[39m=\u001b[39;49mactivity_regularizer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(units) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(units, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m units\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/base_layer.py:340\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m allowed_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    330\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_dim\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    331\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimplementation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m }\n\u001b[1;32m    339\u001b[0m \u001b[39m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m generic_utils\u001b[39m.\u001b[39;49mvalidate_kwargs(kwargs, allowed_kwargs)\n\u001b[1;32m    342\u001b[0m \u001b[39m# Mutable properties\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    346\u001b[0m     \u001b[39misinstance\u001b[39m(trainable, \u001b[39mbool\u001b[39m)\n\u001b[1;32m    347\u001b[0m     \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/generic_utils.py:514\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mfor\u001b[39;00m kwarg \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m kwarg \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_kwargs:\n\u001b[0;32m--> 514\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'kernel_regularizers')"
     ]
    }
   ],
   "source": [
    "#to do regualization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28,1)),#input layer (only sending information so flatten)\n",
    "    Dense(64, activation= 'relu', kernel_regularizers = l2(0.01)),#hidden layer (sending and reciving so dense)\n",
    "    BatchNormalization(),\n",
    "    Dense(10,activation='softmax')#output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0bfbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "#to do batch normalization\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28,1)),#input layer (only sending information so flatten)\n",
    "    Dense(64, activation= 'relu'),#hidden layer (sending and reciving so dense)\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')#output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f20d6",
   "metadata": {},
   "source": [
    "### Tune the parameter in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "286891a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/tomhenehan/Downloads/Code demonstration (6).ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscikit_learn\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2500285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune the layer number and node number\n",
    "\n",
    "def create_model(layer, nodes): #things you want ot tune in parameters\n",
    "    model =Sequential()\n",
    "    model.add(Flatten(input_shape=(28,28,1)))\n",
    "\n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(nodes, activation ='relu'))\n",
    "        model.add(BatchNormalization)\n",
    "    model.add(Dense(10,acttivation ='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss ='categorical_crossentrophy',\n",
    "                  metrics ='accuracy')\n",
    "    return model\n",
    "#if you want to tune optimizer sen in optimizer variable and replace optimizer adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2a67df6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal here. Maybe you meant '==' instead of '='? (486103347.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[39], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    'layers'=[1,2,3],\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "model =KerasClassifier(build_fn =create_model)\n",
    "param_grid={\n",
    "    'layers'=[1,2,3],\n",
    "    'nodes'=['32','64','128']\n",
    "}\n",
    "\n",
    "grid_search =GridSearchCV(estimator= model, param_grid=param_grid, cv =3, n_jobs=-1)\n",
    "grid_result= grid_search.fit(train_images,train_labels)\n",
    "print(grid_result.best_params_)\n",
    "print(grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a4a5bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b1f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6361d6e1",
   "metadata": {},
   "source": [
    "#### Try another data: email data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd405c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3921, 20)\n"
     ]
    }
   ],
   "source": [
    "# Load the email data. Try to fit a neural network to classify the spam. You can\n",
    "#start with a neural network with one hidden layer, and then tune the parameters. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"email.csv\")\n",
    "\n",
    "X = df.drop([\"spam\", \"time\"], axis = 1)\n",
    "y = df['spam']\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c47add7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train,y_test =train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler =StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb7cbeb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tomhenehan/Downloads/Code demonstration (6).ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomhenehan/Downloads/Code%20demonstration%20%286%29.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train_scaled\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aee6dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input =(20,1)),\n",
    "    Dense(16, activation ='relu')\n",
    "    Dense(8,activation='relu'),\n",
    "    Dense(2, activation='sigmoid')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ebc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad455ac",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da29eadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1dbb83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and-evaluate(X,y):\n",
    "#get data\n",
    "#train and test\n",
    "#fit a neural network (output, 1 node, linear activation)\n",
    "# compile (mse)\n",
    "#test, ouput accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f17702",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size=[500,..500000]\n",
    "mse=[]\n",
    "#run the function and record the mse\n",
    "#make a plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac571e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716af030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
